{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Évaluation des modèles BERT et BART"
      ],
      "metadata": {
        "id": "guzZPcTaN-42"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installations et importations"
      ],
      "metadata": {
        "id": "96chNL30ODGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu > /dev/null\n",
        "import sacrebleu\n",
        "\n",
        "!pip install torchmetrics > /dev/null\n",
        "from torchmetrics.functional.text.rouge import rouge_score\n",
        "\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "jDq01IEJ1xDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install errant > /dev/null\n",
        "!python3 -m spacy download en_core_web_sm > /dev/null"
      ],
      "metadata": {
        "id": "dzbgyM6h-LQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxM3Y-AIxDk4"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement de la correction faite par BERT\n",
        "bert_preds = None\n",
        "with open('/content/drive/MyDrive/test.bert.src', 'r') as f:\n",
        "  bert_preds = f.readlines()"
      ],
      "metadata": {
        "id": "PR7jjn40OZN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement de la correction faite par BERT\n",
        "bart_preds = None\n",
        "with open('/content/drive/MyDrive/corrected_BART.txt', 'r') as f:\n",
        "  bart_preds = f.readlines()"
      ],
      "metadata": {
        "id": "wPnyFkn50bvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement de la vérité\n",
        "truths = None\n",
        "with open('/content/drive/MyDrive/output_tgt.txt', 'r') as f:\n",
        "  truths = f.readlines()"
      ],
      "metadata": {
        "id": "LbXksr3U1dfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Évaluation du modèle BERT"
      ],
      "metadata": {
        "id": "Exh1i_BwR4Vi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bleu = sacrebleu.corpus_bleu(bert_preds, [truths])\n",
        "print(bleu)"
      ],
      "metadata": {
        "id": "nVKZB_k9Lb9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(rouge_score(bert_preds, truths))"
      ],
      "metadata": {
        "id": "W4-qF25OLe9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!errant_parallel -orig /content/drive/MyDrive/output_src.txt -cor /content/drive/MyDrive/output_tgt.txt -out truth.m2\n",
        "!errant_parallel -orig /content/drive/MyDrive/output_src.txt -cor /content/drive/MyDrive/test.best.tok -out bert_preds.m2"
      ],
      "metadata": {
        "id": "XwSRPibaLgd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!errant_compare -hyp bert_preds.m2 -ref truth.m2"
      ],
      "metadata": {
        "id": "6i1WP1waLs1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!errant_compare -hyp bert_preds.m2 -ref truth.m2 -dt"
      ],
      "metadata": {
        "id": "VUP2qHoALuBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Évaluation du modèle BART"
      ],
      "metadata": {
        "id": "9-4VkcPrR8uK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bleu = sacrebleu.corpus_bleu(bart_preds, [truths])\n",
        "print(bleu)"
      ],
      "metadata": {
        "id": "5yWENKnF1kZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(rouge_score(bart_preds, truths))"
      ],
      "metadata": {
        "id": "bAQkv6u91_NM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!errant_parallel -orig /content/drive/MyDrive/output_src.txt -cor /content/drive/MyDrive/output_tgt.txt -out truth.m2\n",
        "!errant_parallel -orig /content/drive/MyDrive/output_src.txt -cor /content/drive/MyDrive/corrected_BART.txt -out bart_preds.m2"
      ],
      "metadata": {
        "id": "4CijUy3w-an8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!errant_compare -hyp bart_preds.m2 -ref truth.m2"
      ],
      "metadata": {
        "id": "9qzrLG4aLVFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!errant_compare -hyp bart_preds.m2 -ref truth.m2 -dt"
      ],
      "metadata": {
        "id": "Ap6BLGCE_7Xi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}